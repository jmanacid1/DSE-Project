{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/17/1lp6v8rx7hg46v35nrbf4mk00000gn/T/ipykernel_7843/2340049902.py:1: DtypeWarning: Columns (2088,2089,2092,2097,2100,2101,2141,2152,2153,2154,2157,2158,2167,2185,2201,2202,2203,2204,2205,2206,2207,2208,2216,2219,2220,2221,2222) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('Data/BHCF20250331.txt', delimiter = '^')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Data/BHCF20250331.txt', delimiter = '^')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/17/1lp6v8rx7hg46v35nrbf4mk00000gn/T/ipykernel_7843/3343375304.py:1: DtypeWarning: Columns (2088,2089,2091,2092,2094,2095,2098,2099,2100,2101,2132,2141,2151,2152,2153,2154,2155,2156,2157,2158,2160,2161,2162,2163,2165,2166,2167,2171,2173,2174,2177,2178,2179,2181,2183,2184,2185,2200,2201,2202,2203,2204,2205,2206,2207,2208,2215,2216,2217,2219,2220,2221,2222) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfq2 = pd.read_csv('Data/BHCF20250630 3.txt', delimiter = '^')\n"
     ]
    }
   ],
   "source": [
    "dfq2 = pd.read_csv('Data/BHCF20250630 3.txt', delimiter = '^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['RSSD', 'BHBC', 'BHCA', 'BHCB', 'BHCK', 'BHCM', 'BHCP', 'BHCT', 'BHCW',\n",
      "       'BHCX', 'BHCY', 'BHDM', 'BHFN', 'BHOD', 'BHPA', 'BHPX', 'BHSP', 'BHSX',\n",
      "       'BHTX', 'TEXT'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.str[:4].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dddf = pd.read_csv('/Users/jacksonlipfert/Downloads/MDRM/MDRM_CSV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/17/1lp6v8rx7hg46v35nrbf4mk00000gn/T/ipykernel_7843/756459364.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  short_dddf['Full Code'] = short_dddf['Mnemonic'] + short_dddf['Item Code']\n"
     ]
    }
   ],
   "source": [
    "#dddf.head()\n",
    "short_dddf = dddf[['Mnemonic','Item Code','Item Name']]\n",
    "\n",
    "\n",
    "short_dddf['Full Code'] = short_dddf['Mnemonic'] + short_dddf['Item Code']\n",
    "important_codes = ['RSSD', 'BHBC', 'BHCA', 'BHCB', 'BHCK', 'BHCM', 'BHCP', 'BHCT', 'BHCW',\n",
    "       'BHCX', 'BHCY', 'BHDM', 'BHFN', 'BHOD', 'BHPA', 'BHPX', 'BHSP', 'BHSX',\n",
    "       'BHTX', 'TEXT']\n",
    "short_dddf = short_dddf[short_dddf['Mnemonic'].isin(important_codes)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NET INCOME (LOSS): BHBC4340\n",
      "NET IMPACT ON NET INCOME (BEFORE TAXES) OF THE SALE OF OTHER ASSETS WITH RECOURSE\n",
      "NET IMPACT ON NET INCOME (BEFORE TAXES) OF LOAN ASSETS THAT WERE SOLD WITH RECOURSE\n",
      "NET IMPACT ON NET INCOME (BEFORE TAXES) OF DEFEASED DEBT\n",
      "NET INCOME (LOSS): BHCK4340\n",
      "NET INCOME BEFORE INCOME TAXES; EXTRAORDINARY ITEMS; AND OTHER ADJUSTMENTS ON A FULLY TAXABLE EQUIVALENT BASIS\n",
      "NET INCOME FOR ALL INSURANCE-RELATED ACTIVITIES\n",
      "NET INCOME: BHCKC246\n",
      "NET INCOME: BHCKC250\n",
      "LESS: NET INCOME (LOSS) ATTRIBUTABLE TO NONCONTROLLING (MINORITY) INTERESTS\n",
      "NET INCOME (LOSS) ATTRIBUTABLE TO BANK AND NONCONTROLLING MINORITY INTERESTS\n",
      "NET INCOME FROM SERVICE CORPORATION/SUBSIDIARIES (SEE NOTE BELOW)\n",
      "CASH FLOWS FROM OPERATING ACTIVITIES: ADJUSTMENTS TO RECONCILE NET INCOME TO NET CASH PROVIDED BY OPERATING ACTIVITIES - PROVISION FOR DEFERRED INCOME TAXES\n",
      "CASH FLOWS FROM OPERATING ACTIVITIES: ADJUSTMENTS TO RECONCILE NET INCOME TO NET CASH PROVIDED BY OPERATING ACTIVITIES - (GAIN) OR LOSS ON SALES OF ASSETS\n",
      "CASH FLOWS FROM OPERATING ACTIVITIES: ADJUSTMENTS TO RECONCILE NET INCOME TO NET CASH PROVIDED BY OPERATING ACTIVITIES - EQUITY IN UNDISTRIBUTED (EARNINGS) LOSSES OF SUBSIDIARIES\n",
      "CASH FLOWS FROM OPERATING ACTIVITIES: ADJUSTMENTS TO RECONCILE NET INCOME TO NET CASH PROVIDED BY OPERATING ACTIVITIES - EQUITY IN EXTRAORDINARY ITEMS OF SUBSIDIARIES\n",
      "CASH FLOWS FROM OPERATING ACTIVITIES: ADJUSTMENTS TO RECONCILE NET INCOME TO NET CASH PROVIDED BY OPERATING ACTIVITIES - NET CHANGE IN OTHER LIABILITIES\n",
      "CASH FLOWS FROM OPERATING ACTIVITIES: ADJUSTMENTS TO RECONCILE NET INCOME TO NET CASH PROVIDED BY OPERATING ACTIVITIES - NET CHANGE IN OTHER ASSETS\n",
      "CASH FLOWS FROM OPERATING ACTIVITIES: ADJUSTMENTS TO RECONCILE NET INCOME TO NET CASH PROVIDED BY OPERATING ACTIVITIES - OTHER; NET\n",
      "CASH FLOWS FROM OPERATING ACTIVITIES: ADJUSTMENTS TO RECONCILE NET INCOME TO NET CASH PROVIDED BY OPERATING ACTIVITIES - TOTAL ADJUSTMENTS\n",
      "NET INCOME (LOSS): BHCP4340\n",
      "NET INCOME (LOSS): BHCT4340\n",
      "NET INCOME (LOSS): BHPA4340\n",
      "NET INCOME (LOSS): BHSP4340\n"
     ]
    }
   ],
   "source": [
    "# create mapper\n",
    "\n",
    "\n",
    "column_mapper = {}\n",
    "\n",
    "#Columns that appear across multiple types of companies with the same balance sheet name, need to keep code to disambiguate\n",
    "special_columns = [\n",
    "    'TOTAL ASSETS',\n",
    "    'TOTAL EQUITY',\n",
    "    'TOTAL EQUITY CAPITAL',\n",
    "    'NET INCOME',\n",
    "    'NET INCOME (LOSS)'\n",
    "    ]\n",
    "\n",
    "def get_name_from_full_code(fullcode, df):\n",
    "    '''get column name from full code found in data dictionary'''\n",
    "    column = df['Item Name'][df['Full Code'] == fullcode]\n",
    "    col_name = column.iloc[0]\n",
    "    return col_name\n",
    "\n",
    "\n",
    "#Loop over short data dictionary and populate column mapper with name\n",
    "for code in short_dddf['Full Code']:\n",
    "    column_mapper[code] = get_name_from_full_code(code,short_dddf)\n",
    "\n",
    "\n",
    "def disambiguate_column_mapper(column_mapper, special_columns):\n",
    "    '''Loop over column mapper and replace ambigious columns (found in special_columns)'''\n",
    "\n",
    "    for key,value in column_mapper.items():\n",
    "        if value in special_columns:\n",
    "            column_mapper[key] = f'{value}: {key}' \n",
    "    return column_mapper\n",
    "\n",
    "#Final column mapper\n",
    "disambig_column_mapper = disambiguate_column_mapper(column_mapper, special_columns)\n",
    "\n",
    "#check to make sure columns have been renamed\n",
    "column_name_in_question = 'NET INCOME'\n",
    "for key,value in disambig_column_mapper.items():\n",
    "    if column_name_in_question in str(value):\n",
    "        print(value)\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed_df = df.rename(columns=disambig_column_mapper)\n",
    "renamed_dfq2 = dfq2.rename(columns=disambig_column_mapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['NET INCOME (LOSS)', 'NET INCOME (LOSS)',\n",
      "       'NET INCOME BEFORE INCOME TAXES; EXTRAORDINARY ITEMS; AND OTHER ADJUSTMENTS ON A FULLY TAXABLE EQUIVALENT BASIS',\n",
      "       'NET INCOME', 'NET INCOME',\n",
      "       'LESS: NET INCOME (LOSS) ATTRIBUTABLE TO NONCONTROLLING (MINORITY) INTERESTS',\n",
      "       'NET INCOME (LOSS) ATTRIBUTABLE TO BANK AND NONCONTROLLING MINORITY INTERESTS',\n",
      "       'CASH FLOWS FROM OPERATING ACTIVITIES: ADJUSTMENTS TO RECONCILE NET INCOME TO NET CASH PROVIDED BY OPERATING ACTIVITIES - PROVISION FOR DEFERRED INCOME TAXES',\n",
      "       'CASH FLOWS FROM OPERATING ACTIVITIES: ADJUSTMENTS TO RECONCILE NET INCOME TO NET CASH PROVIDED BY OPERATING ACTIVITIES - (GAIN) OR LOSS ON SALES OF ASSETS',\n",
      "       'CASH FLOWS FROM OPERATING ACTIVITIES: ADJUSTMENTS TO RECONCILE NET INCOME TO NET CASH PROVIDED BY OPERATING ACTIVITIES - EQUITY IN UNDISTRIBUTED (EARNINGS) LOSSES OF SUBSIDIARIES',\n",
      "       'CASH FLOWS FROM OPERATING ACTIVITIES: ADJUSTMENTS TO RECONCILE NET INCOME TO NET CASH PROVIDED BY OPERATING ACTIVITIES - NET CHANGE IN OTHER LIABILITIES',\n",
      "       'CASH FLOWS FROM OPERATING ACTIVITIES: ADJUSTMENTS TO RECONCILE NET INCOME TO NET CASH PROVIDED BY OPERATING ACTIVITIES - NET CHANGE IN OTHER ASSETS',\n",
      "       'CASH FLOWS FROM OPERATING ACTIVITIES: ADJUSTMENTS TO RECONCILE NET INCOME TO NET CASH PROVIDED BY OPERATING ACTIVITIES - OTHER; NET',\n",
      "       'CASH FLOWS FROM OPERATING ACTIVITIES: ADJUSTMENTS TO RECONCILE NET INCOME TO NET CASH PROVIDED BY OPERATING ACTIVITIES - TOTAL ADJUSTMENTS',\n",
      "       'NET INCOME (LOSS)', 'NET INCOME (LOSS)', 'NET INCOME (LOSS)',\n",
      "       'NET INCOME (LOSS)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Column Finder\n",
    "\n",
    "#print(renamed_dfq2.columns.str.contains('NAME'))\n",
    "\n",
    "search_string = 'NET INCOME'\n",
    "matching_columns = renamed_dfq2.columns[renamed_dfq2.columns.str.contains(search_string)]\n",
    "print(matching_columns)\n",
    "#print(renamed_dfq2['REPORTING DATE (CC;YR;MO;DA)'])\n",
    "# i = 0\n",
    "# for name in renamed_dfq2['ENTITY SHORT NAME']:\n",
    "#     i += 1\n",
    "#     if i > 50:\n",
    "#         break\n",
    "#     else:\n",
    "#         print(name)\n",
    "#target_bank = 'FIRST NAT OF NE'\n",
    "#print(renamed_dfq2[renamed_dfq2[\"ENTITY SHORT NAME\"] == target_bank])\n",
    "#print(renamed_df['AVERAGE TOTAL ASSETS (NET OF DEDUCTIONS)'].loc[2])\n",
    "#print(renamed_dfq2['AVERAGE TOTAL ASSETS (NET OF DEDUCTIONS)'].loc[5])\n",
    "#print(renamed_df[\"ENTITY SHORT NAME\"].loc[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so what needs to happen now? I have two dataframes both of which have the same columns and I want to mix them together in such a way that I can compare values across time\n",
    "\n",
    "I have a reporting date which matches the file date which is good. I could union the data and use the bank name and reporting date to compare over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to union\n",
    "union_df = pd.concat([renamed_df, renamed_dfq2], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        assets  dates  net_income\n",
      "ENTITY SHORT NAME                                \n",
      "ACNB CORP             391017.0      2      -141.5\n",
      "CAPITAL ONE FC      87248851.5      2   1517926.0\n",
      "CHOICEONE FS          429414.5      2       448.0\n",
      "CONNECTONE BC        1374685.0      2      4542.0\n",
      "EVERBANK FNCL CORP   3704783.0      2    -37161.0\n",
      "FIRST BUSEY CORP     2296076.0      2     16285.0\n",
      "HOPE BC              2192075.0      2     -9020.0\n",
      "NBT BC               1685470.5      2     -4546.0\n",
      "OLD NAT BC           7330520.5      2    -33795.0\n",
      "UNITED BSHRS         5339495.0      4     -9785.0\n",
      "WESBANCO             3800399.5      2    -33155.0\n"
     ]
    }
   ],
   "source": [
    "#print(union_df[union_df['ENTITY SHORT NAME'] == target_bank])\n",
    "filtered_df = union_df[['ENTITY SHORT NAME','TOTAL EQUITY CAPITAL: BHCK3210','NET INCOME (LOSS): BHBC4340','REPORTING DATE (CC;YR;MO;DA)']].copy()\n",
    "#filtered_df = filtered_df[filtered_df['TOTAL ASSETS'] > 0]\n",
    "#print(filtered_df.head())\n",
    "grouped_df = filtered_df.groupby(['ENTITY SHORT NAME']).agg(\n",
    "    assets = ('TOTAL EQUITY CAPITAL: BHCK3210',\"mean\"),\n",
    "    dates = ('REPORTING DATE (CC;YR;MO;DA)' , 'count'),\n",
    "    net_income = ('NET INCOME (LOSS): BHBC4340', 'mean')\n",
    ")\n",
    "net_income_df = grouped_df[(np.isnan(grouped_df['net_income']) == False) & (grouped_df['net_income'] != 0)]\n",
    "print(net_income_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43    -66310.0\n",
      "767        0.0\n",
      "Name: NET INCOME (LOSS): BHBC4340, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Calculate volitility of earnings\n",
    "\n",
    "VOE_bank = 'WESBANCO'\n",
    "VOE_df = union_df[union_df['ENTITY SHORT NAME'] == VOE_bank]\n",
    "\n",
    "print(VOE_df['NET INCOME (LOSS): BHBC4340'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
